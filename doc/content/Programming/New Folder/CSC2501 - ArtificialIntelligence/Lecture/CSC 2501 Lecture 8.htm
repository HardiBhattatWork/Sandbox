<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0061)http://www.sju.edu/~bforoura/courses/lectures/luger/lab8.html -->
<HTML><HEAD><TITLE>CSC 2501: Lecture 8</TITLE>
<META http-equiv=Content-Type content="text/html; charset=iso-8859-1"><LINK 
href="CSC 2501 Lecture 8_files/style.css" type=text/css rel=stylesheet><!------------------------------------------------------>
<META content="MSHTML 6.00.2900.2802" name=GENERATOR></HEAD>
<BODY>
<DIV align=center>
<TABLE height="100%" cellSpacing=3 cellPadding=3 width="85%" bgColor=silver 
border=0>
  <TBODY>
  <TR>
    <TH>
      <TABLE height="100%" cellSpacing=5 cellPadding=5 width="100%" 
      bgColor=white border=0>
        <TBODY>
        <TR>
          <TD>
            <DIV><B class=a>Lecture 8 (Chapter 10)<BR>Connectionist Machine 
            Learning</B> <BR><BR><BR><IMG height=160 alt=None 
            src="CSC 2501 Lecture 8_files/cover.jpg" width=400 border=0> </DIV><PRE class=a><OL>
<!------------------------------------------------------>
<LI><B class=b>10.0 Introduction</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- Instead of explicit use of symbols in problem solving, we introduce <I>neurally or biologically</I>
   inspired approaches to learning


-- <B>Connectionist learning or parallel distributed process (PDP)</B> approaches de-emphasize 
   the role of symbols in learning and assert that intelligence arises in <B>systems of simple, 
   interacting components</B> called <B>artificial neurons</B>
   


-- <B>Neuronal or connectionist learning</B>:

   -- A process of adaptation in which connections betweens <B>neurons</B> are adjusted

   -- These adaptations are <B>distributed</B> in the sense that they occur across <B>neuronal 
      layers</B>

   -- These adaptations are <B>parallel</B> in the sense that all the neurons within a layer
      process their inputs (<B>stimuli</B>) simultaneously and independently

   -- Problems to be solved must be encoded into numerical patterns, where the encoding
      scheme can play a crucial role in success or failure of the learning system

   

-- <B>Applications of neural networks (NNs)</B>:

   -- Classification/Prediction
   -- Pattern recognition (<B>E.g.</B> spatial or temporal series analyses)
   -- Diagnosis (<B>E.g.</B> Medical, industrial, etc.)
   -- Optimization (<B>E.g.</B> Engineering design)
   -- Finance (<B>E.g.</B> Credit Card Fraud Detection)
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>10.1.1 Early History</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- Let's recall the structure of a <B>biological neuron:</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig1_2.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>Basic Components of an artificial neuron</B>:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_1.jpg" border=0>
</DIV>
<!-- ########################### -->
   (1) <B>Input signals x<SUB>i</SUB></B>
       -- These data come from the environment (<B>stimuli</B>), or the activation of other neurons
       -- Typically, they are discrete, from the set <B>{0,1}</B> or <B>{-1,1}</B> or real numbers


   (2) <B>Weights w<SUB>i</SUB></B>
       -- The weights describe connection or <B>synaptic strengths</B>


   (3) <B>Activation level <IMG src="CSC 2501 Lecture 8_files/sigma.gif" border=0>x<SUB>i</SUB>w<SUB>i</SUB></B>
       -- Its value is determined by the cumulative, weighted strength of its input signals


   (4) <B>Threshold function f</B>
       -- It computes the neuron's final state or output
       -- Its function is to produce <B>on/off</B> neuronal activity (<B>excitatory/inhibitory</B>)
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>The McCulloch-Pitts Neuron</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- MP neuron is the earliest example of neural computing (1943), claimed to be able to
   <B>compute any logical function</B>

   -- <B>Inputs</B> are either excitatory (<B>+1</B>) or inhibitory (<B>-1</B>)

   -- <B>Activation function</B> computes:

       IF <B><IMG src="CSC 2501 Lecture 8_files/sigma.gif" border=0>x<SUB>i</SUB>w<SUB>i</SUB> <IMG src="CSC 2501 Lecture 8_files/ge.gif" border=0> 0</B> THEN <B>Neuron State = +1</B> ELSE <B>Neuron State = -1</B>






-- <B>An Example: The Logical-AND-OR MP Neurons</B>

   -- There is a constant input called <B>bias</B>, which will be useful during the learning 
      algorithm
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_2.jpg" border=0>
</DIV>
<!-- ########################### -->



   -- <B>Activation levels</B> for:

         The <B>AND</B> Neuron: <B><IMG src="CSC 2501 Lecture 8_files/sigma.gif" border=0>x<SUB>i</SUB>w<SUB>i</SUB> = (x)(1)+(y)(1)+(1)(-2) = x + y - 2</B>
         The <B>OR</B> Neuron: <B><IMG src="CSC 2501 Lecture 8_files/sigma.gif" border=0>x<SUB>i</SUB>w<SUB>i</SUB> = (x)(1)+(y)(1)+(1)(-1) = x + y - 1</B>




   -- <B>Threshold rules</B> for:

         The <B>AND</B> Neuron: IF <B>(x + y - 2) <IMG src="CSC 2501 Lecture 8_files/ge.gif" border=0> 0</B> THEN <B>+1</B> ELSE <B>-1</B>
         The <B>OR</B> Neuron: IF <B>(x + y - 1) <IMG src="CSC 2501 Lecture 8_files/ge.gif" border=0> 0</B> THEN <B>+1</B> ELSE <B>-1</B>



   -- <B>The MP model for the logical AND</B>:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/tab10_1.jpg" border=0>
</DIV>
<!-- ########################### -->
   -- <B>What is MP model for the logical OR</B>? There has to be a volunteer for this.




-- <B>Hebb and the Hebbian Learning Model (Rule)</B>:

   -- MP created a fine computational model but offered no learning algorithm for their neuron

   -- The psychologist <B>Hebb (1949)</B> suggested that <B>lea ring</B> occurs in brain through 
      the <B>modification of synaptic strengths</B>

   -- He further speculated that repeated firings across a synapse increased its sensitivity
      and the future likelihood of firing

   -- <B>Hebbian learning rule</B> worked purely on <B>positive reinforcement</B> of used paths 
      and <B>ignored inhibition, punishment for error, or attrition.</B>

   -- Hebb's model fails to produce general results without addition of an inhibitory mechanism, 
      such as the one used in <B>perceptron</B>
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>10.2.1 The Perceptron Training Algorithm</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- In 1958, Rosenblatt devised a learning algorithm for a type of <B>single layer network</B> called
   a <B>perceptron</B>.

   (1) <B>Input signals x<SUB>i</SUB></B>
       -- These data come from the environment (<B>stimuli</B>), or the activation of other neurons
       -- Typically, they are discrete, from the set <B>{0,1}</B> or <B>{-1,1}</B> or real numbers


   (2) <B>Weights w<SUB>i</SUB></B>
       -- The weights describe connection or <B>synaptic strengths</B>


   (3) <B>Activation function</B> computes:

       IF <B><IMG src="CSC 2501 Lecture 8_files/sigma.gif" border=0>x<SUB>i</SUB>w<SUB>i</SUB> <IMG src="CSC 2501 Lecture 8_files/ge.gif" border=0> t</B> THEN <B>+1</B> ELSE <B>-1</B>


   (4) <B>Threshold function f</B>
       -- It computes the neuron's final state or output
       -- Its function is to produce <B>on/off</B> neuronal activity (<B>excitatory/inhibitory</B>)




-- Perceptron uses <B>supervised learning</B>:

   -- Perceptron attempts to solve a problem by producing some result

   -- A teacher gives it the correct result

   -- Perceptron then computes <B>|produced_output - desired_output|</B> and changes its weights 
      to reduce its error 




-- <B>Perceptron training</B>:

   -- Let <B>c</B> = the <B>learning rate</B>
   -- Let <B>d</B> = the <B>desired output value</B>
   -- Let <B>a</B> = the <B>actual (produced) output value = sign(<IMG src="CSC 2501 Lecture 8_files/sigma.gif" border=0>x<SUB>i</SUB>w<SUB>i</SUB>)</B>
      Note that the difference <B>(d-a)</B> is from the set <B>{-2, 0, +2}</B>

   -- The adjustment for the <B>i<SUP>th</SUP></B> weight component:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/eq2.jpg" border=0>
</DIV>
<!-- ########################### -->
   -- The <B>weight adjustment procedure</B>:
      
         IF <B>(d = a)</B> THEN <B>No action necessary</B>
 
         IF <B>(a = -1) &amp;&amp; (d = +1)</B> THEN <B>w<SUB>i</SUB> = w<SUB>i</SUB> + 2cx<SUB>i</SUB></B>

         IF <B>(a = +1) &amp;&amp; (d = -1)</B> THEN <B>w<SUB>i</SUB> = w<SUB>i</SUB> - 2cx<SUB>i</SUB></B>




-- <B>Observations</B>:

   -- The above procedure has the effect of producing a set of weights which are intended to
      <B>minimize the average error over the entire training set</B>

   -- If there is a set of weights which give the correct output for every member of the 
      training set, the perceptron has learned

   -- Perceptrons were initially greeted with a great deal of enthusiasm, but later were shown
      to suffer from <B>one huge limitation</B>: Perceptrons can only learn <B>linearly separable</B>
      problems!
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>Linear Nonseparability</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- An <B>example of nonlinearly separable</B> classification is the <B>XOR function</B>:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/tab10_2.jpg" border=0>
</DIV>
<!-- ########################### -->

-- A perceptron:

        <B>P[x<SUB>1</SUB>, w<SUB>1</SUB>, x<SUB>2</SUB>, w<SUB>2</SUB>, t]</B> 

   to learn the above function, a network must find a weight assignment that satisfies the 
   following:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/eq3.jpg" border=0>
</DIV>
<!-- ########################### -->

-- The <B>problem</B> is that the above <B>equation has no solution,</B> proving that a single-layer
   <B>perceptron cannot learn XOR</B>
  




-- <B>A graphic representation of <U>linear nonseparability</U></B>

   -- It is impossible to draw a 2D line that separates the data point <B>{(0,0), (1,1)}</B> from
      <B>{(0,1), (1,0)}</B> 
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_3.jpg" border=0>
</DIV>
<!-- ########################### -->

   -- In general, we can think of <B>training instances as points in space</B> and the problem of 
      <B>learning</B> a binary classification of these points as the problem of <B>separating these 
      points into two groups</B>

   -- For an <B>n</B> dimensional problem, the classification is linearly separable if its classes
      can be separated by an <B>n - 1</B> dimensional hyperplane.





-- <B>Epilog</B>

   -- Perceptron's limitation to learn only linearly separable function helped opponents of
      the connectionist learning camp get a chance to attack Rosenblatt

   -- Minsky, one of the followers of the symbolic camp, whose research funding had been
      drastically reduced because of the all the connectionist hype at the time, was the
      first to lead the charge (1960s)

   -- Unfortunately, most research in connectionist learning came to a grinding halt until
      1980s when there was a resurgence of connectionist learning (linear inseparability
      problem was then successfully solved by an extension of perceptron called the
      <B>backpropagation</B>)
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>10.2.2 An Example of a Perceptron Classifier</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- <B>An overview of a classification problem</B>

   -- Raw data from a space of possible points are selected (<B>E.g.</B> sound waves from a medical
      device such as an ultrasonic heart monitoring device)

   -- These data are transduced to a new data/pattern space (<B>E.g.</B> a digitized sequence of
      numbers)

   -- In the new space, various features (<B>attributes</B>) are identified (<B>E.g.</B> mean, median,  
      variance, etc.)

   -- The found features are used to classify various input vectors into different classes 
      (<B>E.g. patient_dead, patient_nearly_dead, patient_will_live,</B> etc.</B>)
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_4.jpg" border=0>
</DIV>
<!-- ########################### -->





-- <B>The logistics of the general theory of classification</B>:

   -- Each data grouping that a classifier identifies is represented by a <B>multidimensional
      region in the problem space</B>

   -- Each <B>class R<SUB>i</SUB></B> has a <B>discriminant function g<SUB>i</SUB></B> which measures membership in a 
      specific region

   -- Within region <B>R<SUB>i</SUB></B>, the <B>i<SUP>th</SUP></B> discriminant function has the largest value, i.e.,
            <B>
            <IMG src="CSC 2501 Lecture 8_files/forall.gif" border=0>j<IMG src="CSC 2501 Lecture 8_files/in.gif" border=0>(1,n), g<SUB>i</SUB>(x) &gt; g<SUB>j</SUB>(x)
            </B>

   -- If two regions <B>R<SUB>i</SUB></B> and <B>R<SUB>j</SUB></B> are adjacent, there is a boundary region where <B>g<SUB>i</SUB>(x) = g<SUB>j</SUB>(x)</B>

   -- If <B>the classes are linearly separable</B>, then the discriminant function separating the
      region, <B>g<SUB>i</SUB>(x), is a straight line</B>




-- Consider a hypothetical <B>two-input classification problem</B>:

   -- The <B>two regions of interest</B> are represented as classification <B>labels 1 and -1</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/tab10_3.jpg" border=0>
</DIV>
<!-- ########################### -->

   -- A <B>2D plot</B> of the above data points. Note that the two regions (concepts) of interest 
     <B>are separable by a line</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_5.jpg" border=0>
</DIV>
<!-- ########################### -->





-- <B>How can we compute <I>f(net)</I>?</B>

   -- The perceptron shown below can learn the linear function we are interested in
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_6.jpg" border=0>
</DIV>
<!-- ########################### -->


  -- The above perceptron will learn:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/eq4.jpg" border=0>
</DIV>
<!-- ########################### -->
     where,

         <B>f(x) = +1</B> means <B>x</B> is one class

         <B>f(x) = -1</B> means <B>x</B> is the other class

         The <B>bias</B> serves to shift our <B>linear bipolar</B> thresholding function on the horizontal axis
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 8_files/fig10_7.jpg" border=0>
</DIV>
<!-- ########################### -->





-- <B>Perceptron (Fig. 10.6) training details for the data set from Table 10.3</B>:
   <DIV align=center>
   <TABLE cellSpacing=10 cellPadding=10 width=600 border=0><TBODY><TR bgColor=aliceblue><TH>Iteration</TH><TH>Computation</TH></TR><TR bgColor=whitesmoke><TH vAlign=top>0</TH><TD align=left><PRE>        -- The weight vector <B>W</B> is randomly initialized to <B>[0.75, 0.5, -0.6]</B>
      
        -- The <B>learning rate c = 0.2</B>
        </PRE></TD></TR><TR bgColor=whitesmoke><TH vAlign=top>1</TH><TD align=left><PRE>        -- Let's consider the <B>first data point</B>:
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq5.jpg" border=1>
        <!-- ########################### -->

        -- Since <B>f(net) = 1</B>, we do not need to adjust <B>W</B>. Thus, <B>W<SUP>2</SUP> = W<SUP>1</SUP></B> 
       </PRE></TD></TR><TR bgColor=whitesmoke><TH vAlign=top>2</TH><TD><PRE>        -- The <B>second data point</B>:
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq6.jpg" border=1>
        <!-- ########################### -->

        -- Here, <B>f(net) = 1</B> while it should have been <B>-1</B>, so we must 
           apply the learning rule:
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq2.jpg" border=1>
        <!-- ########################### -->

        -- Therefore,
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq7.jpg" border=1>
        <!-- ########################### -->
        
        -- But since <B>d<SUP>2</SUP> - sign(W<SUP>2</SUP>*X<SUP>2</SUP>) = -2</B>, we get
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq8.jpg" border=1>
        <!-- ########################### -->

        </PRE></TD></TR><TR bgColor=whitesmoke><TH vAlign=top>3</TH><TD align=left><PRE>        -- Now, the <B>third data point</B>:
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq9.jpg" border=1>
        <!-- ########################### -->

        -- Again, the net result is not the desired output, so we must adjust 
           weights
        <!-- ########################### -->
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<IMG src="CSC 2501 Lecture 8_files/eq10.jpg" border=1>
        <!-- ########################### -->
       </PRE></TD></TR><TR bgColor=whitesmoke><TH vAlign=top>4...499</TH><TD align=left><PRE>        -- Same as the steps shown above
       </PRE></TD></TR><TR bgColor=whitesmoke><TH vAlign=top>500</TH><TD align=left><PRE>        -- Perceptron is done learning because the weight vector 
           <B>W</B> converges to <B>[-1.3, -1.1, 10.9]</B>

        -- The <B>line separating the two classes +1 and -1</B> is thus defined as:

               <B>
               f(net) = W.X = -1.3*x<SUB>1</SUB> - 1.1*x<SUB>2</SUB> + 10.9
               </B>
       </PRE></TD></TR></TBODY></TABLE>
   </DIV>
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>Exercise 1</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- Similar to the example covered above, show traces of perceptron training for logic
   functions <B>AND, OR</B> and <B>XOR</B>

-- Clearly if you have been to class and alert, you realize that <B>AND</B> and <B>OR</B> functions 
   are linearly separable, and that a suitable weight vector should be found in only a few 
   iterations. 

-- For the <B>XOR</B> function, however, you just need to demonstrate nonconvergence.
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
</LI></OL></PRE></TD></TR></TBODY></TABLE></TH></TR></TBODY></TABLE></DIV></BODY></HTML>
