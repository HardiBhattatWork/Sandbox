<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0061)http://www.sju.edu/~bforoura/courses/lectures/luger/lab5.html -->
<HTML><HEAD><TITLE>CSC 2501: Lecture 5</TITLE>
<META http-equiv=Content-Type content="text/html; charset=iso-8859-1"><LINK 
href="CSC 2501 Lecture 5_files/style.css" type=text/css rel=stylesheet><!------------------------------------------------------>
<META content="MSHTML 6.00.2900.2802" name=GENERATOR></HEAD>
<BODY>
<DIV align=center>
<TABLE height="100%" cellSpacing=3 cellPadding=3 width="85%" bgColor=silver 
border=0>
  <TBODY>
  <TR>
    <TH>
      <TABLE height="100%" cellSpacing=5 cellPadding=5 width="100%" 
      bgColor=white border=0>
        <TBODY>
        <TR>
          <TD>
            <DIV><B class=a>Lecture 5 (Chapter 4)<BR>Heuristic Search</B> 
            <BR><BR><BR><IMG height=160 alt=None 
            src="CSC 2501 Lecture 5_files/cover.jpg" width=400 border=0> </DIV><PRE class=a><OL>
<!------------------------------------------------------>
<LI><B class=b>4.0 Introduction</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- <B>Taxonomy of Search</B>

   (1) <B>Blind, uninformed, or brute-force</B> E.g. DFS, BFS, random-walk, etc.

   (2) <B>Informed or heuristic-driven</B> E.g. Best-first (BEST), A*, etc.



-- What is a <B>heuristic?</B>:

   -- The study of the methods and rules of discovery and invention

   -- Rules for selecting those branches in the search tree that are <B>most likely to produce 
      an acceptable solution</B>

   -- A <I>hunch, intuition</I> or <I>rule of thumb</I>. Employed in game playing, theorem proving, 
      and expert systems to <B>prune space of possible solutions</B>



-- <B>Why do we need heuristics?</B>

   -- A problem <B>may not have an exact solution</B> or may be vague. E.g. In medical 
      diagnosis, a given set of symptoms may be due to several causes. Doctors use 
      heuristics to select the most likely diagnosis

   -- A problem <B>may have an exact solution, but the computational cost of finding it 
      may be prohibitive</B>. E.g. <I>Brute-force</I> approaches such as <B>DFS</B> of <B>BFS</B> will not 
      work in the game of chess as <I>the state space explodes exponentially</I>



-- <B>Pitfalls of heuristics</B>

   -- An informed guess may be fallible

   -- They use limited information so they can not predict exact behavior of a system

   -- They can lead to suboptimal solution regions or fail altogether



-- An example: <B>tic-tac-toe</B>

   -- Combinatorics of exhaustive search (<B>a total of 9! states</B>) are high but not 
      insurmountable

   -- <B>Symmetry reduction</B> decreases the search space. E.g. There are actually 3 and
      not 9 initial moves due to symmetry considerations:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_1.jpg" border=0>
</DIV>
<!-- ########################### -->

   -- The <B>most wins</B> heuristic:

      -- Eliminate most search by moving into a configuration where <B>X</B> has the most
         winning lines (center position)
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_2.jpg" border=0>
</DIV>
<!-- ########################### -->

     -- Thus, 2/3 of the moves can be eliminated using the <B>most wins</B> stratagem
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_3.jpg" border=0>
</DIV>
<!-- ########################### -->
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.1.1 Implementing "Best-First" Search (BEST)</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- <B>Hill climbing</B> is needed to implement <B>BEST</B>:

   -- Expand current search state and evaluate its children

   -- The <B>best child</B> is selected for further expansion, retaining neither any of its siblings or
      parents.

   -- Analogous to a strategy used by a <B>blind mountain climber</B>: go uphill along the steepest 
      path until you can go no farther




-- <B>Pitfalls of hill climbing</B>:

   -- Since no history of moves is maintained, it <B>cannot recover from failure</B>

   -- It can get stuck at local optimal because it halts at a state which has a better
      evaluation than any of its children

   -- E.G. In 8-puzzle it may be necessary to shuffle many tiles which may already be
      in their final position in order to reach the goal state. Here, <B>better</B> is definitely 
      <B>not the best</B> in an absolute sense (Quick fix: <B>random perturbation</B>)




-- <B>Summary of hill climbing</B>:

   -- Despite its limitations, it is still widely used

   -- It can become efficient if the evaluation function is sufficiently informative to avoid
      local extrema in the solution space and infinite paths

   -- <B>BEST</B> uses hill climbing in addition to a <B>priority queue</B> to recover from local optima     
      (inferior solutions)
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>The BEST Algorithm</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- <B>Maintained lists:</B>

  (1)  <B>open</B>: 
       -- Keeps track of the current search front along with some measure of <B>fitness</B>
       -- Only the most promising states are considered
       -- When sorted, it is referred to as a <B>priority queue</B>

  (2) <B>closed</B>: 
      -- Records already visited states.




-- <B>The algorithm:</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4a.jpg" border=0>
</DIV>
<!-- ########################### -->



-- <B>A hypothetical search space and its trace</B>:

   -- Assume <B>P</B> is the goal state, thus states along the path to it have lower heuristic values

   -- The heuristic is <B>fallible</B> because state <B>O</B> has a lower value than the goal itself

   -- Unlike hill climbing, BEST recovers from this error by its use of the priority queue
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_4.jpg" border=0>
</DIV>
<!-- ########################### -->
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4b.jpg" border=0>
</DIV>
<!-- ########################### -->


   -- Note the frontiers of <B>open</B> and <B>closed</B> lists and see how uneven it is. That implies
      <B>BEST is highly opportunistic</B>

   -- Although BEST selects the most promising states on <B>open</B> to expand, it does not abandon
      the unchosen ones on <B>open</B>

   -- In the event the algorithm results in failure somewhere down a branch, it retrieves the 
      <B>next best state</B> previously generated and saved on <B>open</B>

   -- In below, <B>children(B)</B> were found to have poor heuristics, the search's focus shifts
      to <B>state C</B>. The children of <B>B</B>, however, are kept on <B>open</B> for possible future
      expansions.
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_5.jpg" border=0>
</DIV>
<!-- ########################### -->
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>A Minor Variation of BEST in Lisp</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- <B>The Main Algorithm:</B>

	(1) Form the sorted set {N}

	(2) If N = nil Then exit(failure)

	(3) n = first_node(N), N = N-{n}

	(4) If goal(n) Then exit(success)

	(5) Else
		N = {children(n)} + N
		Sort N based on distance from goal (<B>heuristic</B>)
		Goto step 2




-- <B>The Search Space</B>:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4bb.jpg" border=0>
</DIV>
<!-- ########################### -->
   




-- <B>The Lisp Implementation of BEST</B> (The <A href="http://www.sju.edu/~bforoura/courses/lectures/luger/utilities/prog3.lsp">source code</A>)

<B>;;*** The tree</B>
(setq <B>tree</B>  '(((()D()) B (()E()))   A   ((()F()) C (()G()))))

<B>;;*** Node costs</B>
(setq <B>costs</B> '((A 6) (B 3) (C 1) (D 5) (E 4) (F 2) (G 0)))

<B>;;*** Find cost of a node</B>
(defun <B>findcost</B> (item)
   (second (assoc item costs))
)

<B>;;*** Find the left subtree</B>
(defun <B>ltree</B> (tree) (first tree))

<B>;;*** Find the node data</B>
(defun  <B>data</B> (tree) (second tree))

<B>;;*** Find the right subtree</B>
(defun <B>rtree</B> (tree) (car (last tree)))

<B>;;*** Find the children of a given node</B>
(defun <B>child</B> (tree item)
   (cond
     ((null tree) nil)
     ((and (equal (car item) (data tree)) 
           (not (equal (second (ltree tree)) nil))   <B>;;cannot sort nil values!</B>
      ) 
      (list (list (second (ltree tree)) (findcost (second (ltree tree))))
            (list (second (rtree tree)) (findcost (second (rtree tree))))
      )
     )
     ( t    (or (<B>child</B> (ltree tree) item) (<B>child</B>(rtree tree) item))
   )
)

<B>;;*** Do the best-first search</B>
(defun <B>best</B> (nodes goal)
   (format t "~s ~%" nodes)
   (cond
     ((null nodes) nil)
     ((equal (caar nodes) goal) (caar nodes))
     (t  (<B>best</B> 
             (sort 
                 (append (child tree (car nodes)) (rest nodes)) '&lt; :key #'second) goal)
     )
   )
)




<B>Sample Runs</B>
<B>===========</B>
&gt; <B>costs</B>
((A 6) (B 3) (C 1) (D 5) (E 4) (F 2) (G 0))


&gt; (<B>sort</B> costs '&lt; :key #'second)
((G 0) (C 1) (F 2) (B 3) (E 4) (D 5) (A 6))


&gt; (<B>child</B> tree '(A 6))
((B 3) (C 1))


&gt; (<B>child tree</B> '(F 2))
NIL


&gt; (<B>best</B> '((A 6)) 'g)		;; <B>note that goal exists</B>
((A 6)) 
((C 1) (B 3)) 
((G 0) (F 2) (B 3)) 
G


&gt; (<B>best</B> '((A 6)) 'w)		;; <B>note that goal does not exist</B>
((A 6)) 
((C 1) (B 3)) 
((G 0) (F 2) (B 3)) 
((F 2) (B 3)) 
((B 3)) 
((E 4) (D 5)) 
((D 5)) 
NIL                                    ;; <B>note the expansion order: ACGFBED</B>
</PRE></TD></TR></TBODY></TABLE>


<!------------------------------------------------------>
<LI><B class=b>4.1.2 Implementing Heuristic Evaluation Functions</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- Let us now examine the utility of a few evaluation functions for the game of 8-puzzle

-- Here is a sample game with a start state, a goal state, and the first 3 states:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_6.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>Two possibilities for a heuristic</B>:

   (1) <B>A simple heuristic</B>
       -- Count <I>number of tiles out of place</I> compared to the goal
       -- Seems simple and intuitive
       -- <B>Uninformed</B> because it does not use all the information available in a state

   (2) <B>A better heuristic</B>
       -- Sum all distances by which the tiles are out of place, <I>one for each square a 
          tile must be moved to reach its final position</I>




-- <B>Shortcomings of above heuristics</B>:

   -- They both fail to consider the difficulty of <B>tile reversals</B>, i.e., 2 tiles are 
      next to each other but the goal states requires their being in opposite locations

   -- Swapping two tiles takes more than just 2 moves; it may take many moves because the
      two tiles have to go around each other
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_7.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>Yet another heuristic!</B>:

   -- Let's consider the above difficulty

   -- <B>h()</B> = 2 <U>times</U> each direct tile reversal




-- <B>Summary of all the heuristic functions</B>:

     -- <B>sum of distances</B> heuristic seems to best capture the dynamics of the game

     -- <B>direct tile reversal</B> heuristic is meaningless here
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_8.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>What's the point of all this?</B>

   -- Good heuristics are hard to come by

   -- We need to make intelligent choices in presence of limited (missing) information

   -- Design of a <B>good heuristic</B> is more <B>empirical</B> but it should rely on judgment and 
      intuition

   -- A rotten heuristic will lead a very decent search algorithm stray

   -- True mettle of a good heuristic: <B>Performance</B>

   -- Opt for <B>Dynamic programming</B> when creating your evaluation functions




-- <B>Dynamic programming:</B>

   -- Take into consideration that the <I>optimum path</I> from a start state to some goal state
      must pass through some intermediate state

   -- The problem is now to recursively find the optimum path between the start state and
      some intermediate state

   -- This observation makes our evaluation function <B>f()</B>:

         <B>f(n) = g(n) + h(n)</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4bbb.jpg" border=0>
</DIV>
<!-- ########################### -->
      where,
   
         <B>S</B>: Start state
         <B>G</B>: Goal state
         <B>n</B>: Some intermediate state

         <B>f(n)</B>: d(S, G) = the distance between S and G that is to be optimized
         <B>g(n)</B>: d(S, n) = the actual distance between S and n
         <B>h(n)</B>: d(n, G) = the heuristic value for reaching G through n




-- <B>Back to 8-puzzle</B>:
   
   -- <B>g()</B> is incremented by 1 for each level of search since it records the actual number
      of moves that have been used to go from the start state to some other state

   -- Here, let <B>h() = # misplaced tiles</B>

   -- <B>Adding g() to h()</B> has the effect of favoring <B>shallower paths in the graph</B>

   -- Below, see three child states and their corresponding <B>f()</B> values
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_9.jpg" border=0>
</DIV>
<!-- ########################### -->


   

-- <B>The full BEST search of the 8-puzzle graph:</B>

   -- Numbers atop states indicate the order in which they were taken off <B>open</B>

   -- Unnumbered states were still on <B>open</B> when algorithm terminated

   -- In <B>Step 3</B>:
      -- Since <B>f(e) = f(f) = 5</B>, children of <B>f</B> are examined first

      -- Although <B>state h</B> has the same <B>h()</B> as <B>state f</B>, BEST
         selects <B>state f</B> for examination because of its shallower depth

      -- In fact, the <B>g()</B> component of <B>f()</B> gives the search a <B>breadth-first</B> flavor

      -- If a <B>h()</B> functions continuously returns <B>good</B> values for all states along
         a certain path that is not reaching the goal, the <B>g()</B> value will eventually dominate
         <B>f()</B> and force search to go back toward shorter solution paths

      -- We will see later how BEST can be guaranteed to produce the shortest path to the  
         goal
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_10.jpg" border=0>
</DIV>
<!-- ########################### -->


-- <B>Successive stages of <U>open</U> and <U>closed</U> that generate the above graph:</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4c.jpg" border=0>
</DIV>
<!-- ########################### -->


-- <B><U>open</U> and <U>closed</U> on the 3rd iteration of the heuristic search</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_11.jpg" border=0>
</DIV>
<!-- ########################### -->
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.2 Admissibility, Monotonicity, and Informedness</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- We may wish to evaluate the behavior of <B>h()</B> based on different criteria

   -- <B>Any soution</B> will do

   -- <B>Only the shortest solution</B> will do (excessive costs associated with every step)



-- Always remember that <B>a heuristic is</B>:

   -- <B>Admissible</B> if it can find the shortest path whenever one exists

   -- <B>More informed</B> when it outperforms others

   -- <B>Monotone</B> when a state is discovered by using <B>h()</B>, the same state will not be reached 
      later in the search at a cheaper cost
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.2.1 Admissibility Measures</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- A search algorithm is <B>admissible</B> if it <B>is guaranteed to find a minimal solution path 
   when one exists</B>

-- BFS is admissible because it expands states at <B>level n</B> before moving to states at <B>level 
   n+1</B>. However, if you recall, <B>BFS is terribly inefficient</B>.



-- Properties of <B>admissible h()</B>:

         <B>f*(n) = g*(n) + h*(n)</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4bbbb.jpg" border=0>
</DIV>
<!-- ########################### -->
   where,
         <B>S</B>: Start state
         <B>G</B>: Goal state
         <B>n</B>: Some intermediate state

         <B>g*(n):</B> Cost of the <B>shortest path</B> from S to n
         <B>h*(n):</B> Actual cost of the <B>shortest path</B> from n to G
         <B>f*(n):</B> Actual cost of the <B>optimal path</B> from S to G through n




-- <B>Observations</B>:
  
   -- <B>BEST + f* = Admissible</B>

   -- Unfortunately, <I>oracles such as f*</I> do not exist for most real-world problems so we would 
      like for <B>f</B> to be a close estimate of <B>f*</B>

   -- Similarly, <B>g</B> is a close estimate of <B>g*</B> since it is plausible <B>g(n)<IMG src="CSC 2501 Lecture 5_files/ge.gif" border=0>g*(n)</B>

   -- By the same token we can replace <B>h*</B> by <B>h</B>, which is a <B>heuristic estimate</B> of the
      minimal cost to a goal state

   


-- <B>Algorithms A &amp; A*</B>:

   -- <B>A = BEST + dynamic programming</B>

   -- <B>A* = BEST + dynamic programming</B> + and if <B>h(n)<IMG src="CSC 2501 Lecture 5_files/le.gif" border=0>h*(n)</B>

   -- <B>All A* algorithms are admissible</B>

   -- E.g. BFS with <B>f(n) = g(n) + 0</B>




-- Examples of <B>admissible heuristics</B>:

   -- <B>h(n) = the number of misplaced tiles</B> 
      because <B>h(n) <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> Number of moves required to reach the goal state</B>


   -- <B>h(n) = the sum of distances</B> 
      because <B>h(n) <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> The actual minimum path cost</B>
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.2.2 Monotonicity</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- A* does not require that <B>g(n) = g*(n)</B>, i.e., an admissible <B>h()</B> may initially reach
   non-goal states along a suboptimal path

-- <B>Local Admissibility:</B> An algorithm finds the minimal path to each state it encounters in the
   search

-- A heuristic function <B>h()</B> is said to be <B>monotone</B> if it is everywhere admissible, reaching 
   each state along the shortest path from its ancestors. More formally, 
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4b5.jpg" border=0>
</DIV>
<!-- ########################### -->
   (1) <B><IMG src="CSC 2501 Lecture 5_files/forall.gif" border=0>n<SUB>i</SUB> <IMG src="CSC 2501 Lecture 5_files/forall.gif" border=0>n<SUB>j</SUB> h(n<SUB>i</SUB>) - h(n<SUB>j</SUB>) <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> cost(n<SUB>i</SUB>,n<SUB>j</SUB>)</B> 

   (2) <B>h(Goal) = 0</B>





-- What does the term <B>monotone</B> have to do with this?

  -- As the search moves through the space, <B>h()</B> for each state <B>n</B> is replaced by the actual cost
     for generating that path

  -- Because the actual cost is always larger or equal, <B>f()</B> will not decrease, i.e., <B>f() will
     be monotonically nondecreasing</B>

   


-- Why are monotonic heuristic functions admissible?
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4b6.jpg" border=0>
</DIV>
<!-- ########################### -->
   From S<SUB>1</SUB> to S<SUB>2</SUB>: <B>h(S<SUB>1</SUB>) - h(S<SUB>2</SUB>) <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> cost(S<SUB>1</SUB>,S<SUB>2</SUB>)</B>  (by definition of monotonicity)
   From S<SUB>2</SUB> to S<SUB>3</SUB>: <B>h(S<SUB>2</SUB>) - h(S<SUB>3</SUB>) <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> cost(S<SUB>2</SUB>,S<SUB>3</SUB>)</B>  
   ...
   From S<SUB>g-1</SUB> to S<SUB>g</SUB>: <B>h(S<SUB>g-1</SUB>) - h(S<SUB>g</SUB>) <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> cost(S<SUB>g-1</SUB>,S<SUB>g</SUB>)</B>  
   <HR align=left width=400>
   From S<SUB>1</SUB> to S<SUB>g</SUB>: <B>h(S<SUB>1</SUB>) - 0 <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> cost(S<SUB>1</SUB>,S<SUB>g</SUB>)</B>  

   <IMG src="CSC 2501 Lecture 5_files/hence.gif" border=0> <B>h is A* and admissible</B>
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.2.3 Informedness</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- <B>Informedness</B>

   For two <B>A*</B> heuristics <B>h<SUB>1</SUB></B> and <B>h<SUB>2</SUB></B>, 
   if
        <B>h<SUB>1</SUB>(n)</B> <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> <B>h<SUB>2</SUB>(n)</B> <IMG src="CSC 2501 Lecture 5_files/forall.gif" border=0>n in search space
   then
        <B>h<SUB>2</SUB></B> is said to be more <B>informed than <B>h<SUB>1</SUB></B> </B>



-- 8-puzzle example:

   -- Recall that <B>BFS</B> = <B>A* with heuristic h<SUB>1</SUB> such that h<SUB>1</SUB>(x)=0 <IMG src="CSC 2501 Lecture 5_files/forall.gif" border=0>x</B>

   -- Also recall that the heuristic <B>h<SUB>2</SUB> = #misplaced tiles</B> is a lower bound for h*

   -- Since <B>h<SUB>1</SUB> <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> h<SUB>2</SUB> <IMG src="CSC 2501 Lecture 5_files/le.gif" border=0> h*</B>, we say that <B>num-of-misplaced-tiles heuristic is more informed 
      than BFS</B>

   -- In diagram below, note that both <B>h<SUB>1</SUB></B> and <B>h<SUB>2</SUB></B> find the optimal path, but <B>h<SUB>2</SUB></B> evaluates 
      many fewer states 

<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_12.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>Observations</B>:

   -- The more informed an A* algorithm, the less space it needs to expand to get the optimal
      solution

   -- Two approaches to the game of chess (trade-off):

      (1) Use <B>simple heuristics</B> but rely on <B>computer speed and memory</B> to go deep
          into the solution space


      (2) Use <B>sophisticated heuristics</B> but do not have to go deep into the solution space
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.3.1 The Minimax Procedure</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- Games have always been an important application area for heuristic algorithms

-- Let us first examine th <B>game of nim</B> whose search space is small enough to be exhaustively
   searched



-- Rules of <B>nim</B>:

   -- Place all tokens on a table between the two opponents
   -- At each move, the player must divide the pile of tokens into 2 nonempty piles of different 
      sizes
   -- E.g. 6 tokens into 2 piles (5,1) or (4,2) but not (3,3)
   -- The 1st player who can't make a move loses



-- An example: <B>nim with 7 tokens</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_13.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>Main considerations in 2-person games</B>:

   -- Although state space may be tractable, the main difficulty is in anticipating the opponent's 
      actions

   -- Assume your opponent is smart and that they use the same knowledge as you

   -- <I>Minimax</I> provides a reasonable basis for predicting an opponent's behavior




-- <B>Minimax</B>

   -- The opponents are <B>MAX (the player we want to win)</B> and <B>MIN</B>

   -- We label each level of the search space according to whose run is in the game

   -- Each leaf is given a value of <B>1 or 0</B>, depending on whether it is a win for <B>MAX(1)</B> or
      <B>MIN(0)</B>

   -- Propagate these values up the graph through parents using the rule:

           <B>If n is a MAX (MIN) node, then give it the max (min) of all its child values</B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_14.jpg" border=0>
</DIV>
<!-- ########################### -->

   -- The above rule, then, allows minimax to select the best move based on the propagated 
      values

   -- Note that regardless of <B>MIN</B>'s 1st move, <B>MAX</B> can always force the game to a win. 

   -- <B>MIN</B> will win if <B>MAX</B> plays foolishly 
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
<LI><B class=b>4.3.2 Minimaxing to Fixed Ply Depth</B>

<TABLE width="90%" bgColor=white border=1><TBODY><TR><TD><PRE>-- In more complicated games, it's impossible to expand the state space graph to leaf nodes

-- Thus, it will be more practical to expand search to some predefined level <B>n</B>. This strategy 
   is called the <B>n-ply look-ahead</B>

   -- <B>n</B> is the number of explored levels

   -- Leaves of the graph are not the final states, so they cannot be assigned win or loss values

   -- Instead, <B>each leaf node is assigned a heuristic evaluation function</B>

   -- The <B>evaluation values are propagated back to the root</B> as a measure of the best 
      achievable state after <B>n</B> moves

   -- The diagram below depicts minimax on a hypothetical state space with a <I>4-ply look-ahead</I>:
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_15.jpg" border=0>
</DIV>
<!-- ########################### -->




-- <B>Observations:</B>

   -- Evaluations to a fixed ply depth can be very misleading

   -- E.g. If a move in chess offers a rook as a lure to take the opponent's queen a few levels
      deeper, then the evaluation may be biased in favor of taking the rook

   -- This is called the <B>horizon effect</B> since we can not afford to arbitrarily increase 
      the ply depth

  


-- <B>An application to Tic-Tac-Toe</B>:

   -- The heuristic:
      (1) Takes a state <B>n</B> that is to be evaluated
      (2) Counts all winning lines <B>M(n)</B> open to <B>MAX</B> 
      (3) Counts all winning lines <B>O(n)</B> open to <B>MIN</B>
      (4) Forms the difference <B>E(n) = M(n) - O(n)</B> 
      (5) Tries to maximize <B>E(n)</B>

      (6) A forced win for <B>MAX</B> gets the evaluation value <B>+<IMG src="CSC 2501 Lecture 5_files/inf.gif" border=0></B>
      (7) A forced win for <B>MIN</B> gets the evaluation value <B>-<IMG src="CSC 2501 Lecture 5_files/inf.gif" border=0></B>
<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_16.jpg" border=0>
</DIV>
<!-- ########################### -->





-- <B>An example of 2-ply minimax</B>:

<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_17.jpg" border=0>
</DIV>
<!-- ########################### -->

<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_18.jpg" border=0>
</DIV>
<!-- ########################### -->

<!-- ########################### -->
<DIV align=center>
<IMG src="CSC 2501 Lecture 5_files/fig4_19.jpg" border=0>
</DIV>
<!-- ########################### -->
</PRE></TD></TR></TBODY></TABLE>

<!------------------------------------------------------>
</LI></OL></PRE></TD></TR></TBODY></TABLE></TH></TR></TBODY></TABLE></DIV></BODY></HTML>
